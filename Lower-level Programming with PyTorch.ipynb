{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower-level Programming with PyTorch\n",
    "\n",
    "Let's dig just a little deeper. We'll first get the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from make_face_dataset import make_dataset\n",
    "\n",
    "\n",
    "act = ['Fran Drescher', 'America Ferrera', 'Kristin Chenoweth', 'Alec Baldwin', 'Bill Hader', 'Steve Carell']\n",
    "train_x, train_y = make_dataset(range(100), act)\n",
    "test_x, test_y = make_dataset(range(100,120),act)\n",
    "\n",
    "dim_x = 1024\n",
    "dim_h = 20\n",
    "dim_out = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,  let's define `Variable`s containing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_float = torch.FloatTensor\n",
    "\n",
    "x = Variable(torch.from_numpy(train_x), requires_grad=False).type(dtype_float)\n",
    "y = Variable(torch.from_numpy(train_y.astype(float)), requires_grad=False).type(dtype_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b0 = Variable(torch.randn((1, dim_h)), requires_grad=True)\n",
    "W0 = Variable(torch.randn((dim_x, dim_h)), requires_grad=True)\n",
    "\n",
    "b1 = Variable(torch.randn((1, dim_out)), requires_grad=True)\n",
    "W1 = Variable(torch.randn((dim_h, dim_out)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that everything is accessible right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.3389  1.9895  0.0045 -0.0334 -1.5259  2.0825  0.7016  2.3932 -0.1088  0.6518\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.6502  1.4249  1.0805 -2.4361 -1.2705  0.1939 -1.0271  0.7681 -0.3775  0.0505\n",
       "[torch.FloatTensor of size 1x20]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the the model. Note that since we'll want to reuse it for different inputs, we'll want it to be in a function (or really in a class -- we'll show how to do that later). First, we'll remind ourselves of the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([600, 1024]), torch.Size([1, 20]), torch.Size([1024, 20]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data.shape, b0.data.shape, W0.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6]), torch.Size([20, 6]), torch.Size([600, 6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.data.shape, W1.data.shape, y.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x, b0, W0, b1, W1):\n",
    "    h = torch.matmul(x, W0) + b0.repeat(x.data.shape[0], 1)\n",
    "    out = torch.matmul(h, W1) + b1.repeat(h.data.shape[0], 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_out = model(x, b0, W0, b1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logSoftMax = torch.nn.LogSoftmax() # We'll be too lazy to define this one by hand\n",
    "loss = -torch.mean(torch.sum(y * logSoftMax(y_out), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 47.8923\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "\n",
    "for t in range(1000):\n",
    "    y_out = model(x, b0, W0, b1, W1)\n",
    "    loss = -torch.mean(torch.sum(y * logSoftMax(y_out), 1))\n",
    "    loss.backward()\n",
    "    b0.data -= learning_rate * b0.grad.data\n",
    "    W0.data -= learning_rate * W0.grad.data\n",
    "    \n",
    "    b1.data -= learning_rate * b1.grad.data\n",
    "    W1.data -= learning_rate * W1.grad.data\n",
    "    \n",
    "    \n",
    "    b0.grad.data.zero_()\n",
    "    W0.grad.data.zero_()\n",
    "    b1.grad.data.zero_()\n",
    "    W1.grad.data.zero_()\n",
    "    \n",
    "    #print(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_all_var = Variable(torch.from_numpy(test_x), requires_grad=False).type(dtype_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_out = model(x_test_all_var, b0, W0, b1, W1).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 3, 0, 1, 1, 1, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 3, 5, 2, 3, 5, 3, 3, 3, 0,\n",
       "       3, 3, 3, 2, 5, 5, 3, 3, 3, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 1, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 5, 2, 1, 5, 5, 4, 5, 5, 5, 5, 1, 5, 5, 2, 5,\n",
       "       5, 2, 2, 5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test_out, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
